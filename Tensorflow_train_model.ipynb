{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import data_provider\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_ROOT = 'imagenet/train/' # ADJUST\n",
    "TRAIN_LIST_FILE = 'imagenet/train.txt' # ADJUST\n",
    "\n",
    "BATCH_SIZE = 64  # ADJUST\n",
    "CROP_SIZE = 224 # ADJUST\n",
    "CLASSES = [281, 239] # Tabby cat, Bernese mountain dog\n",
    "LR_START = 0.01 # ADJUST\n",
    "LR_END = LR_START / 1e4 # ADJUST\n",
    "MOMENTUM = 0.9 # ADJUST\n",
    "NUM_EPOCHS = 1000 # ADJUST\n",
    "OUTPUT_ROOT = 'output/vggA_BN' # ADJUST\n",
    "LOG_EVERY_N = 10 # ADJUST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preapre training data queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 2600\n",
      "Number of train iterations: 40625\n"
     ]
    }
   ],
   "source": [
    "train_image, train_label, num_samples = data_provider.imagenet_data(\n",
    "    TRAIN_DATA_ROOT,\n",
    "    TRAIN_LIST_FILE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    crop_size=(CROP_SIZE, CROP_SIZE),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "iters = NUM_EPOCHS * num_samples // BATCH_SIZE\n",
    "print('Number of train samples: {}'.format(num_samples))\n",
    "print('Number of train iterations: {}'.format(iters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('net'):\n",
    "    logits = model.model(train_image, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "        labels=train_label, logits=logits)\n",
    "_=tf.summary.scalar('loss/loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training parameters and structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "lr = tf.train.polynomial_decay(LR_START, global_step, iters, LR_END)\n",
    "tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=MOMENTUM)\n",
    "train_op = slim.learning.create_train_op(loss, \n",
    "    optimizer, global_step=global_step)\n",
    "\n",
    "supervisor = tf.train.Supervisor(logdir=OUTPUT_ROOT,\n",
    "    global_step=global_step,\n",
    "    save_summaries_secs=60, # ADJUST\n",
    "    save_model_secs=300, # ADJUST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path output/vggA_BN/model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "[0 / 40625] loss_net = 0.7757963538169861\n",
      "[10 / 40625] loss_net = 1.2651417255401611\n",
      "[20 / 40625] loss_net = 1.0054584741592407\n",
      "[30 / 40625] loss_net = 0.6220829486846924\n",
      "And so on...\n"
     ]
    }
   ],
   "source": [
    "with supervisor.managed_session() as sess:\n",
    "\n",
    "    start_iter = sess.run(global_step)\n",
    "    for it in range(start_iter, iters):\n",
    "\n",
    "        loss_value = sess.run(train_op)\n",
    "\n",
    "        if it % LOG_EVERY_N == 0:\n",
    "            print('[{} / {}] loss_net = {}'.format(it, iters, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
